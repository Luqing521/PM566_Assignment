HW04
================
Luqing Ren

# Problem 1: Make sure your code is nice

``` r
# Total row sums
 fun1 <- function(mat) { n <- nrow(mat)
 ans <- double(n)
 for (i in 1:n) {
   ans[i] <- sum(mat[i, ]) 
  }
 ans 
}
 fun1alt <- function(mat) { 
 rowSums(mat)
 }
 #Cumulative sum by row
 fun2 <- function(mat) {
  n <- nrow(mat)
  k <- ncol(mat)
  ans <- mat
  for (i in 1:n) {
    for (j in 2:k) {
      ans[i,j] <- mat[i, j] + ans[i, j - 1]
    }
  }
  ans
}
fun2alt <- function(mat){
  matrixStats::rowCumsums(mat)
}
# Use the data with this code
set.seed(2315)
dat <- matrix(rnorm(200 * 100), nrow = 200)

# Test for the first
microbenchmark::microbenchmark(
  fun1(dat),
  fun1alt(dat), unit = "relative", check = "equivalent"
)
```

    ## Unit: relative
    ##          expr      min       lq     mean   median       uq      max neval cld
    ##     fun1(dat) 10.58873 11.63238 7.279397 10.19341 12.40485 1.809671   100   b
    ##  fun1alt(dat)  1.00000  1.00000 1.000000  1.00000  1.00000 1.000000   100  a

``` r
# Test for the second
microbenchmark::microbenchmark(
  fun2(dat),
  fun2alt(dat), unit = 'relative', check = 'equivalent'
)
```

    ## Unit: relative
    ##          expr      min       lq     mean  median       uq      max neval cld
    ##     fun2(dat) 27.80725 24.84522 14.59645 21.0546 16.82819 5.259692   100   b
    ##  fun2alt(dat)  1.00000  1.00000  1.00000  1.0000  1.00000 1.000000   100  a

# Problem 2:Make things run faster with parallel computing

``` r
sim_pi <- function(n = 1000, i = NULL) {
  p <- matrix(runif(n*2), ncol = 2)
  mean(rowSums(p^2) < 1) * 4
}

# Here is an example of the run
set.seed(156)
sim_pi(1000) # 3.132
```

    ## [1] 3.132

In order to get accurate estimates, we can run this function multiple
times, with the following code:

``` r
# This runs the simulation a 4,000 times, each with 10,000 points

set.seed(1231)
system.time({
  ans <- unlist(lapply(1:4000, sim_pi, n = 10000))
  print(mean(ans))
})
```

    ## [1] 3.14124

    ##    user  system elapsed 
    ##   5.026   1.528   7.519

Rewrite the previous code using parLapply() to make it run faster.

``` r
library(parallel)
cl <- makePSOCKcluster(4)
clusterSetRNGStream(cl, 123)
clusterExport(cl,varlist = c("sim_pi"), envir = environment())

system.time({
  ans <- unlist(parLapply(cl, 1:4000, sim_pi, n = 10000))
  print(mean(ans))
  stopCluster(cl)
})
```

    ## [1] 3.141482

    ##    user  system elapsed 
    ##   0.008   0.001   3.022

# SQL

``` r
# install.packages(c("RSQLite", "DBI"))
library(RSQLite)
library(DBI)
# Initialize a temporary in memory database
con <- dbConnect(SQLite(), ":memory:")
# Download tables
film <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/film.csv")
film_category <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/film_category.csv")
category <- read.csv("https://raw.githubusercontent.com/ivanceras/sakila/master/csv-sakila-db/category.csv")
# Copy data.frames to database
dbWriteTable(con, "film", film)
dbWriteTable(con, "film_category", film_category)
dbWriteTable(con, "category", category)
```

# Question 1:How many many movies is there avaliable in each rating catagory

``` sql
SELECT COUNT(*) AS n_rows,rating
FROM film
GROUP BY rating
```

<div class="knitsql-table">

| n\_rows | rating |
| ------: | :----- |
|     180 | G      |
|     210 | NC-17  |
|     194 | PG     |
|     223 | PG-13  |
|     195 | R      |

5 records

</div>

# Question 2:What is the average replacement cost and rental rate for each rating category.

``` sql
SELECT rating,
       AVG(replacement_cost) AS ave_cost,
       AVG(rental_rate) AS ave_rate
FROM film
GROUP BY rating
```

<div class="knitsql-table">

| rating | ave\_cost | ave\_rate |
| :----- | --------: | --------: |
| G      |  20.12333 |  2.912222 |
| NC-17  |  20.13762 |  2.970952 |
| PG     |  18.95907 |  3.051856 |
| PG-13  |  20.40256 |  3.034843 |
| R      |  20.23103 |  2.938718 |

5 records

</div>

# Question 3:Use table film\_category together with film to find the how many films there are witth each category ID

``` sql
SELECT COUNT(*) AS num_films, category_id
FROM film
  INNER JOIN  film_category
ON film.film_id = film_category.film_id
GROUP BY category_id
```

<div class="knitsql-table">

| num\_films | category\_id |
| ---------: | -----------: |
|         64 |            1 |
|         66 |            2 |
|         60 |            3 |
|         57 |            4 |
|         58 |            5 |
|         68 |            6 |
|         62 |            7 |
|         69 |            8 |
|         73 |            9 |
|         61 |           10 |

Displaying records 1 - 10

</div>

# Question 4:Incorporate table category into the answer to the previous question to find the name of the most popular category.

``` sql
SELECT (name) AS most_popular,
max(num_films) AS num_films
FROM
(SELECT COUNT(*) AS num_films, category_id
FROM film
  INNER JOIN  film_category
ON film.film_id = film_category.film_id
GROUP BY category_id ) AS new
INNER JOIN category
ON new.category_id = category.category_id
```

<div class="knitsql-table">

| most\_popular | num\_films |
| :------------ | ---------: |
| Sports        |         74 |

1 records

</div>
